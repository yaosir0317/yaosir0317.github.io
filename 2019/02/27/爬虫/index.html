<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
      
    
    
      
    
  <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
  <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-flash.min.css" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
    
  
  <link href="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css">







  

<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Python,">










<meta name="description" content="什么是爬虫爬虫就是通过编写程序模拟浏览器上网，然后让其去互联网上抓取数据的过程。">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="基于Python的爬虫之一">
<meta property="og:url" content="https://yaosir0317.github.io/2019/02/27/爬虫/index.html">
<meta property="og:site_name" content="YaoSir">
<meta property="og:description" content="什么是爬虫爬虫就是通过编写程序模拟浏览器上网，然后让其去互联网上抓取数据的过程。">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-03-23T09:00:54.799Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于Python的爬虫之一">
<meta name="twitter:description" content="什么是爬虫爬虫就是通过编写程序模拟浏览器上网，然后让其去互联网上抓取数据的过程。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://yaosir0317.github.io/2019/02/27/爬虫/">





  <title>基于Python的爬虫之一 | YaoSir</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">YaoSir</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The philosophers have only interpreted the world in various ways - the point however is to change it.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-首页">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于">
          <a href="/about/" rel="section">
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-标签">
          <a href="/tags/" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-归档">
          <a href="/archives/" rel="section">
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yaosir0317.github.io/2019/02/27/爬虫/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="yaosir0317">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YaoSir">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">基于Python的爬虫之一</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-27T16:36:06+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="什么是爬虫"><a href="#什么是爬虫" class="headerlink" title="什么是爬虫"></a>什么是爬虫</h1><p>爬虫就是通过编写程序模拟浏览器上网，然后让其去互联网上抓取数据的过程。</p>
<a id="more"></a>
<h1 id="哪些语言可以实现爬虫"><a href="#哪些语言可以实现爬虫" class="headerlink" title="哪些语言可以实现爬虫"></a>哪些语言可以实现爬虫</h1><p><strong>php</strong>：可以实现爬虫，但是php在实现爬虫中支持多线程和多进程方面做的不好。</p>
<p><strong>java</strong>：可以实现爬虫。java可以非常好的处理和实现爬虫，是唯一可以与python并驾齐驱且是python的头号劲敌。但是java实现爬虫代码较为臃肿，重构成本较大。</p>
<p><strong>c/c++</strong>：可以实现爬虫。但是使用这种方式实现爬虫纯粹是是某些人（大佬们）能力的体现，却不是明智和合理的选择。</p>
<p><strong>python</strong>：可以实现爬虫。python实现和处理爬虫语法简单，代码优美，支持的模块繁多，学习成本低，具有非常强大的框架（scrapy等）！</p>
<h1 id="爬虫的分类"><a href="#爬虫的分类" class="headerlink" title="爬虫的分类"></a>爬虫的分类</h1><h2 id="通用爬虫"><a href="#通用爬虫" class="headerlink" title="通用爬虫"></a>通用爬虫</h2><p>通用爬虫是搜索引擎（Baidu、Google、Yahoo等）“抓取系统”的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。  简单来讲就是尽可能的；把互联网上的所有的网页下载下来，放到本地服务器里形成备分，在对这些网页做相关处理(提取关键字、去掉广告)，最后提供一个用户检索接口。 </p>
<h2 id="聚焦爬虫"><a href="#聚焦爬虫" class="headerlink" title="聚焦爬虫"></a>聚焦爬虫</h2><p>聚焦爬虫是根据指定的需求抓取网络上指定的数据。例如：获取豆瓣上电影的名称和影评，而不是获取整张页面中所有的数据值。</p>
<h1 id="robots-txt协议"><a href="#robots-txt协议" class="headerlink" title="robots.txt协议"></a>robots.txt协议</h1><p>如果自己的门户网站中的指定页面中的数据不想让爬虫程序爬取到的话，那么则可以通过编写一个robots.txt的协议文件来约束爬虫程序的数据爬取。robots协议的编写格式可以观察淘宝网的robots（访问<a href="http://www.taobao.com/robots.txt即可）。但是需要注意的是，该协议只是相当于口头的协议，并没有使用相关技术进行强制管制(防君子不防小人)" target="_blank" rel="noopener">www.taobao.com/robots.txt即可）。但是需要注意的是，该协议只是相当于口头的协议，并没有使用相关技术进行强制管制(防君子不防小人)</a>.</p>
<h1 id="反爬虫"><a href="#反爬虫" class="headerlink" title="反爬虫"></a>反爬虫</h1><p>门户网站通过相应的策略和技术手段，防止爬虫程序进行网站数据的爬取。</p>
<h1 id="反反爬虫"><a href="#反反爬虫" class="headerlink" title="反反爬虫"></a>反反爬虫</h1><p>爬虫程序通过相应的策略和技术手段，破解门户网站的反爬虫手段，从而爬取到相应的数据。</p>
<h1 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h1><p>requests模块是python中原生的基于网络请求的模块，其主要作用是用来模拟浏览器发起请求。功能强大，用法简洁高效。在爬虫领域中占据着重要的地位。</p>
<h2 id="请求载体身份标识的伪装："><a href="#请求载体身份标识的伪装：" class="headerlink" title="请求载体身份标识的伪装："></a>请求载体身份标识的伪装：</h2><ul>
<li>User-Agent：请求载体身份标识，通过浏览器发起的请求，请求载体为浏览器，则该请求的User-Agent为浏览器的身份标识，使用爬虫程序发起的请求，则该请求的载体为爬虫程序，则该请求的User-Agent为爬虫程序的身份标识。可以通过判断该值来获知该请求的载体究竟是基于哪款浏览器还是基于爬虫程序。</li>
<li>反爬机制：某些门户网站会对访问该网站的请求中的User-Agent进行捕获和判断，如果该请求的UA为爬虫程序，则拒绝向该请求提供数据。</li>
<li>反反爬策略：将爬虫程序的UA伪装成某一款浏览器的身份标识。</li>
</ul>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">requests.get(url, params,data, headers, proxies)  # url地址/get携带的参数/post的参数/请求头信息/代理</span><br><span class="line">requests.get()  # get请求获取</span><br><span class="line">requests.post()  # post请求获取</span><br><span class="line">requests.get().text  # 返回原网页内容</span><br><span class="line">requests.get().content  # 返回二进制</span><br><span class="line">requests.get().json()  # 返回json数据</span><br></pre></td></tr></table></figure>
<h1 id="正解解析"><a href="#正解解析" class="headerlink" title="正解解析"></a>正解解析</h1><h2 id="常用正则表达式"><a href="#常用正则表达式" class="headerlink" title="常用正则表达式"></a>常用正则表达式</h2><p><strong>常用元字符</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">.</th>
<th>匹配除换行符以外的任意字符</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">\w</td>
<td>匹配字母或数字或下划线</td>
</tr>
<tr>
<td style="text-align:center">\s</td>
<td>匹配任意的空白符</td>
</tr>
<tr>
<td style="text-align:center">\d</td>
<td>匹配数字</td>
</tr>
<tr>
<td style="text-align:center">\b</td>
<td>匹配单词的开始或结束</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td>匹配字符串的开始</td>
</tr>
<tr>
<td style="text-align:center">$</td>
<td>匹配字符串的结束</td>
</tr>
</tbody>
</table>
<p><strong>常用限定符</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">*</th>
<th>重复零次或更多次</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">+</td>
<td>重复一次或更多次</td>
</tr>
<tr>
<td style="text-align:center">?</td>
<td>重复零次或一次</td>
</tr>
<tr>
<td style="text-align:center">{n}</td>
<td>重复n次</td>
</tr>
<tr>
<td style="text-align:center">{n,}</td>
<td>重复n次或更多次</td>
</tr>
<tr>
<td style="text-align:center">{n,m}</td>
<td>重复n到m次</td>
</tr>
</tbody>
</table>
<p><strong>常用反义词</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">\W</th>
<th>匹配任意不是字母，数字，下划线，汉字的字符</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">\S</td>
<td>匹配任意不是空白符的字符</td>
</tr>
<tr>
<td style="text-align:center">\D</td>
<td>匹配任意非数字的字符</td>
</tr>
<tr>
<td style="text-align:center">\B</td>
<td>匹配不是单词开头或结束的位置</td>
</tr>
<tr>
<td style="text-align:center">[^x]</td>
<td>匹配除了x以外的任意字符</td>
</tr>
<tr>
<td style="text-align:center">[^aeiou]</td>
<td>匹配除了aeiou这几个字母以外的任意字符</td>
</tr>
</tbody>
</table>
<p><strong>特殊</strong>(包括python的re模块)</p>
<table>
<thead>
<tr>
<th style="text-align:center">(ab)</th>
<th>分组</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.*</td>
<td>贪婪匹配</td>
</tr>
<tr>
<td style="text-align:center">.*?</td>
<td>惰性匹配</td>
</tr>
<tr>
<td style="text-align:center">re.I</td>
<td>忽略大小写</td>
</tr>
<tr>
<td style="text-align:center">re.M</td>
<td>多行匹配</td>
</tr>
<tr>
<td style="text-align:center">re.S</td>
<td>单行匹配</td>
</tr>
<tr>
<td style="text-align:center">re.sub</td>
<td>正则表达式, 替换内容, 字符串</td>
</tr>
</tbody>
</table>
<h1 id="Xpath解析"><a href="#Xpath解析" class="headerlink" title="Xpath解析"></a>Xpath解析</h1><h2 id="常用xpath表达式"><a href="#常用xpath表达式" class="headerlink" title="常用xpath表达式"></a>常用xpath表达式</h2><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 属性定位： </span></span><br><span class="line">    <span class="string">'''找到class属性值为song的div标签'''</span></span><br><span class="line">    //div[@class="song"] </span><br><span class="line"><span class="comment"># 层级&amp;索引定位：</span></span><br><span class="line">    <span class="string">'''找到class属性值为tang的div的直系子标签ul下的第二个子标签li下的直系子标签a'''</span></span><br><span class="line">    //div[@class="tang"]/ul/li[2]/a</span><br><span class="line"><span class="comment"># 逻辑运算：</span></span><br><span class="line">    <span class="string">'''找到href属性值为空且class属性值为du的a标签'''</span></span><br><span class="line">    //a[@href="" and @class="du"]</span><br><span class="line"><span class="comment"># 模糊匹配：</span></span><br><span class="line">    //div[contains(@class, "ng")]</span><br><span class="line">    //div[starts-with(@class, "ta")]</span><br><span class="line"><span class="comment"># 取文本：</span></span><br><span class="line">    <span class="string">'''/表示获取某个标签下的文本内容</span></span><br><span class="line"><span class="string">       //表示获取某个标签下的文本内容和所有子标签下的文本内容'''</span></span><br><span class="line">    //div[@class="song"]/p[1]/text()</span><br><span class="line">    //div[@class="tang"]//text()</span><br><span class="line"><span class="comment"># 取属性：</span></span><br><span class="line">    //div[@class="tang"]//li[2]/a/@href</span><br></pre></td></tr></table></figure>
<h2 id="etree"><a href="#etree" class="headerlink" title="etree"></a>etree</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># 将html文档或者xml文档转换成一个etree对象，然后调用对象中的方法查找指定的节点</span></span><br><span class="line"><span class="comment"># 本地文件：</span></span><br><span class="line">	tree = etree.parse(文件名)</span><br><span class="line">	tree.xpath(<span class="string">"xpath表达式"</span>)</span><br><span class="line"><span class="comment"># 网络数据</span></span><br><span class="line">	tree = etree.HTML(网页内容字符串)</span><br><span class="line">	tree.xpath(<span class="string">"xpath表达式"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用xpath对url_conten进行解析</span></span><br><span class="line"><span class="comment"># 使用xpath解析从网络上获取的数据</span></span><br><span class="line">tree=etree.HTML(url_content)</span><br><span class="line"><span class="comment"># 解析获取当页所有的标题</span></span><br><span class="line">title_list=tree.xpath(<span class="string">'xpath表达式'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="BeautifulSoup解析"><a href="#BeautifulSoup解析" class="headerlink" title="BeautifulSoup解析"></a>BeautifulSoup解析</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure>
<h2 id="使用-2"><a href="#使用-2" class="headerlink" title="使用"></a>使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(<span class="string">'字符串类型或者字节类型'</span>, <span class="string">'lxml'</span>)</span><br><span class="line">（<span class="number">1</span>）根据标签名查找</span><br><span class="line">    - soup.a   只能找到第一个符合要求的标签</span><br><span class="line">（<span class="number">2</span>）获取属性</span><br><span class="line">    - soup.a.attrs  获取a所有的属性和属性值，返回一个字典</span><br><span class="line">    - soup.a.attrs[<span class="string">'href'</span>]   获取href属性</span><br><span class="line">    - soup.a[<span class="string">'href'</span>]   也可简写为这种形式</span><br><span class="line">（<span class="number">3</span>）获取内容</span><br><span class="line">    - soup.a.string</span><br><span class="line">    - soup.a.text</span><br><span class="line">    - soup.a.get_text()</span><br><span class="line">    【注意】如果标签还有标签，那么string获取到的结果为<span class="keyword">None</span>，而其它两个，可以获取文本内容</span><br><span class="line">（<span class="number">4</span>）find：找到第一个符合要求的标签</span><br><span class="line">    - soup.find(<span class="string">'a'</span>)  找到第一个符合要求的</span><br><span class="line">    - soup.find(<span class="string">'a'</span>, title=<span class="string">"xxx"</span>)</span><br><span class="line">    - soup.find(<span class="string">'a'</span>, alt=<span class="string">"xxx"</span>)</span><br><span class="line">    - soup.find(<span class="string">'a'</span>, class_=<span class="string">"xxx"</span>)</span><br><span class="line">    - soup.find(<span class="string">'a'</span>, id=<span class="string">"xxx"</span>)</span><br><span class="line">（<span class="number">5</span>）find_all：找到所有符合要求的标签</span><br><span class="line">    - soup.find_all(<span class="string">'a'</span>)</span><br><span class="line">    - soup.find_all([<span class="string">'a'</span>,<span class="string">'b'</span>]) 找到所有的a和b标签</span><br><span class="line">    - soup.find_all(<span class="string">'a'</span>, limit=<span class="number">2</span>)  限制前两个</span><br><span class="line">（<span class="number">6</span>）根据选择器选择指定的内容</span><br><span class="line">    select:soup.select(<span class="string">'#feng'</span>)</span><br><span class="line">        - 常见的选择器：标签选择器(a)、类选择器(.)、id选择器(<span class="comment">#)、层级选择器</span></span><br><span class="line">            - 层级选择器：</span><br><span class="line">            div .dudu <span class="comment">#lala .meme .xixi  下面好多级</span></span><br><span class="line">            div &gt; p &gt; a &gt; .lala          只能是下面一级</span><br><span class="line">【注意】select选择器返回永远是列表，需要通过下标提取指定的对象</span><br></pre></td></tr></table></figure>
<h1 id="图片懒加载"><a href="#图片懒加载" class="headerlink" title="图片懒加载"></a>图片懒加载</h1><p>图片懒加载是一种网页优化技术。图片作为一种网络资源，在被请求时也与普通静态资源一样，将占用网络资源，而一次性将整个页面的所有图片加载完，将大大增加页面的首屏加载时间。为了解决这种问题，通过前后端配合，使图片仅在浏览器当前视窗内出现时才加载该图片，达到减少首屏图片请求数的技术就被称为“图片懒加载”。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>在网页源码中，在img标签中首先会使用一个“伪属性”（通常使用src2，original……）去存放真正的图片链接而并非是直接存放在src属性中。当图片出现到页面的可视化区域中，会动态将伪属性替换成src属性，完成图片的加载。</p>
<h1 id="图片验证码"><a href="#图片验证码" class="headerlink" title="图片验证码"></a>图片验证码</h1><p>云打码/打码兔</p>
<h2 id="处理验证码的实现流程"><a href="#处理验证码的实现流程" class="headerlink" title="处理验证码的实现流程"></a>处理验证码的实现流程</h2><blockquote>
<ul>
<li><p>对携带验证码的页面数据进行抓取</p>
</li>
<li><p>可以将页面数据中验证码进行解析，验证码图片下载到本地</p>
</li>
<li><p>可以将验证码图片提交给三方平台进行识别，返回验证码图片上的数据值</p>
<p>  云打码平台：</p>
<ol>
<li>在官网中进行注册（普通用户和开发者用户）</li>
<li>登录开发者用户：<ul>
<li>实例代码的下载+开发文档</li>
<li>创建一个软件</li>
<li>使用示例代码中的源码文件中的代码进行修改，让其识别验证码图片中的数据值</li>
</ul>
</li>
</ol>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#该函数就调用了打码平台的相关的接口对指定的验证码图片进行识别，返回图片上的数据值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCode</span><span class="params">(codeImg)</span>:</span></span><br><span class="line">    <span class="comment"># 云打码平台普通用户的用户名</span></span><br><span class="line">    username    = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 云打码平台普通用户的密码</span></span><br><span class="line">    password    = <span class="string">''</span>                            </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 软件ＩＤ，开发者分成必要参数。登录开发者后台【我的软件】获得！</span></span><br><span class="line">    appid       =                                      </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 软件密钥，开发者分成必要参数。登录开发者后台【我的软件】获得！</span></span><br><span class="line">    appkey      = <span class="string">''</span>    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证码图片文件</span></span><br><span class="line">    filename    = codeImg                        </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证码类型，# 例：1004表示4位字母数字，不同类型收费不同。请准确填写，否则影响识别率。在此查询所有类型 http://www.yundama.com/price.html</span></span><br><span class="line">    codetype    = <span class="number">3000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 超时时间，秒</span></span><br><span class="line">    timeout     = <span class="number">20</span>                                    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查</span></span><br><span class="line">    <span class="keyword">if</span> (username == <span class="string">'username'</span>):</span><br><span class="line">        print(<span class="string">'请设置好相关参数再测试'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 初始化</span></span><br><span class="line">        yundama = YDMHttp(username, password, appid, appkey)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 登陆云打码</span></span><br><span class="line">        uid = yundama.login();</span><br><span class="line">        print(<span class="string">'uid: %s'</span> % uid)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 查询余额</span></span><br><span class="line">        balance = yundama.balance();</span><br><span class="line">        print(<span class="string">'balance: %s'</span> % balance)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始识别，图片路径，验证码类型ID，超时时间（秒），识别结果</span></span><br><span class="line">        cid, result = yundama.decode(filename, codetype, timeout);</span><br><span class="line">        print(<span class="string">'cid: %s, result: %s'</span> % (cid, result))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>用云打码+session爬取人人网个人信息页</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">session = requests.Session()</span><br><span class="line">url = <span class="string">"http://www.renren.com/SysHome.do"</span></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 获取验证码</span></span><br><span class="line">code_obj = requests.get(url=url, headers=header).text</span><br><span class="line">tree = etree.HTML(code_obj)</span><br><span class="line">code_url = tree.xpath(<span class="string">'//*[@id="verifyPic_login"]/@src'</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 保存验证码</span></span><br><span class="line">urllib.request.urlretrieve(code_url,<span class="string">"code.jpg"</span>)</span><br><span class="line"><span class="comment"># 识别验证码(code_content:用上面文档所封装的函数)</span></span><br><span class="line">code_content = identity_code(<span class="string">"code.jpg"</span>, <span class="number">2004</span>)</span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">"captcha_type"</span>:<span class="string">"web_login"</span>,</span><br><span class="line">    <span class="string">"domain"</span>:<span class="string">"renren.com"</span>,</span><br><span class="line">    <span class="string">"email"</span>:<span class="string">"13183355361"</span>,</span><br><span class="line">    <span class="string">"f"</span>:<span class="string">"http%3A%2F%2Fwww.renren.com%2F969892425"</span>,</span><br><span class="line">    <span class="string">"icode"</span>:code_content,</span><br><span class="line">    <span class="string">"key_id"</span>:<span class="string">"1"</span>,</span><br><span class="line">    <span class="string">"origURL"</span>:<span class="string">"http://www.renren.com/home"</span>,</span><br><span class="line">    <span class="string">"password"</span>:<span class="string">"05ef6d3441bc78ba004cb8a7bb3dd60165ec17bc270aaf1e3e37448fb6e9f1c1"</span>,</span><br><span class="line">    <span class="string">"rkey"</span>:<span class="string">"948db2d8639bcd2664994c49454256d1"</span></span><br><span class="line">&#125;</span><br><span class="line">login_url = <span class="string">"http://www.renren.com/ajaxLogin/login?1=1&amp;uniqueTimestamp=2019141515944"</span></span><br><span class="line"><span class="comment"># 该次请求产生的cookie会被自动存储到session对象中</span></span><br><span class="line">session.post(url=login_url, data=data, headers=header).text</span><br><span class="line">profile_url = <span class="string">"http://www.renren.com/969892425/profile"</span></span><br><span class="line"><span class="comment"># 爬取目标页的信息</span></span><br><span class="line">page_text = session.get(url=profile_url, headers=header).text</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"renren.html"</span>,<span class="string">"w"</span>,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(page_text)</span><br></pre></td></tr></table></figure>
<h1 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h1><p>selenium是Python的一个第三方库，对外提供的接口可以操作浏览器，然后让浏览器完成自动化的操作。　</p>
<p>而我们就可以通过浏览器的自动化操作应付懒加载类问题.</p>
<h2 id="浏览器的驱动程序（以谷歌浏览器为例）"><a href="#浏览器的驱动程序（以谷歌浏览器为例）" class="headerlink" title="浏览器的驱动程序（以谷歌浏览器为例）"></a>浏览器的驱动程序（以谷歌浏览器为例）</h2><p>谷歌浏览器驱动下载地址：<code>http://chromedriver.storage.googleapis.com/index.html</code></p>
<p>版本映射表:  <code>http://blog.csdn.net/huilan_same/article/details/51896672</code></p>
<h2 id="使用-3"><a href="#使用-3" class="headerlink" title="使用"></a>使用</h2><blockquote>
<p>find_element_by_id                    根据id找节点<br>find_elements_by_name             根据name找<br>find_elements_by_xpath                根据xpath查找<br>find_elements_by_tag_name         根据标签名找<br>find_elements_by_class_name       根据class名字查找</p>
<p>driver.find_element_by_link_text()    定位文字链接</p>
<p>switch_to.frame(‘login_frame’)         定位到一个具体的iframe</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># 浏览器驱动位置，记得前面加r'','r'是防止字符转义的</span></span><br><span class="line">chr_obj = webdriver.Chrome(<span class="string">r'驱动程序路径'</span>)</span><br><span class="line"><span class="comment"># 用get打开百度页面</span></span><br><span class="line">chr_obj.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line"><span class="comment"># 查找页面的“设置”选项，并进行点击</span></span><br><span class="line">chr_obj.find_elements_by_link_text(<span class="string">'设置'</span>)[<span class="number">0</span>].click()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># # 打开设置后找到“搜索设置”选项，设置为每页显示50条</span></span><br><span class="line">chr_obj.find_elements_by_link_text(<span class="string">'搜索设置'</span>)[<span class="number">0</span>].click()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选中每页显示50条</span></span><br><span class="line">m = chr_obj.find_element_by_id(<span class="string">'nr'</span>)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line">m.find_element_by_xpath(<span class="string">'//*[@id="nr"]/option[3]'</span>).click()</span><br><span class="line">m.find_element_by_xpath(<span class="string">'.//option[3]'</span>).click()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 点击保存设置</span></span><br><span class="line">chr_obj.find_elements_by_class_name(<span class="string">"prefpanelgo"</span>)[<span class="number">0</span>].click()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理弹出的警告页面   确定accept() 和 取消dismiss()</span></span><br><span class="line">chr_obj.switch_to_alert().accept()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 找到百度的输入框，并输入 女神</span></span><br><span class="line">chr_obj.find_element_by_id(<span class="string">'kw'</span>).send_keys(<span class="string">'女神'</span>)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 点击搜索按钮</span></span><br><span class="line">chr_obj.find_element_by_id(<span class="string">'su'</span>).click()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 在打开的页面中找到，并打开这个页面</span></span><br><span class="line">chr_obj.find_elements_by_link_text(<span class="string">'女神_百度图片'</span>)[<span class="number">0</span>].click()</span><br><span class="line">sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">chr_obj.quit()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打开窗口</span></span><br><span class="line">browser.get(<span class="string">"https://www.baidu.com/"</span>)</span><br><span class="line"><span class="comment"># 打开新窗口</span></span><br><span class="line">newwindow = <span class="string">'window.open("https://www.baidu.com");'</span></span><br><span class="line">browser.execute_script(newwindow)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 切换到新的窗口</span></span><br><span class="line">handles = browser.window_handles</span><br><span class="line">browser.switch_to_window(handles[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<h2 id="phantomJs"><a href="#phantomJs" class="headerlink" title="phantomJs"></a>phantomJs</h2><p>PhantomJS是一款无界面的浏览器，其自动化操作流程和上述操作谷歌浏览器是一致的。由于是无界面的，为了能够展示自动化操作流程，PhantomJS为用户提供了一个截屏的功能，使用save_screenshot函数实现。(因为我们不可能让用户去看着浏览器自动操作,所以要用无界面)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">'https://movie.douban.com/typerank?type_name=%E6%81%90%E6%80%96&amp;type=20&amp;interval_id=100:90&amp;action='</span></span><br><span class="line">    <span class="comment"># 发起请求前，可以让url表示的页面动态加载出更多的数据</span></span><br><span class="line">    path = <span class="string">r'C:\Users\Administrator\Desktop\ziliao\phantomjs-2.1.1-windows\bin\phantomjs.exe'</span></span><br><span class="line">    <span class="comment"># 创建无界面的浏览器对象</span></span><br><span class="line">    bro_obj = webdriver.PhantomJS(path)</span><br><span class="line">    <span class="comment"># 发起url请求</span></span><br><span class="line">    bro_obj.get(url)</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 截图</span></span><br><span class="line">    bro_obj.save_screenshot(<span class="string">'1.png'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 执行js代码（让滚动条向下偏移n个像素（作用：动态加载了更多的电影信息））</span></span><br><span class="line">    js = <span class="string">'window.scrollTo(0,document.body.scrollHeight)'</span></span><br><span class="line">    bro_obj.execute_script(js)  <span class="comment"># 该函数可以执行一组字符串形式的js代码</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    bro_obj.execute_script(js)  <span class="comment"># 该函数可以执行一组字符串形式的js代码</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    bro_obj.save_screenshot(<span class="string">'2.png'</span>) </span><br><span class="line">    time.sleep(<span class="number">2</span>) </span><br><span class="line">    <span class="comment"># 使用爬虫程序爬去当前url中的内容 </span></span><br><span class="line">    html_source = bro_obj.page_source <span class="comment"># 该属性可以获取当前浏览器的当前页的源码（html） </span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./source.html'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f: </span><br><span class="line">        f.write(html_source) </span><br><span class="line">    bro_obj.quit()</span><br></pre></td></tr></table></figure>
<h2 id="谷歌无头浏览器"><a href="#谷歌无头浏览器" class="headerlink" title="谷歌无头浏览器"></a>谷歌无头浏览器</h2><p>由于PhantomJs最近已经停止了更新和维护，所以推荐大家可以使用谷歌的无头浏览器，是一款无界面的谷歌浏览器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 创建一个参数对象，用来控制chrome以无界面模式打开</span></span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">'--disable-gpu'</span>)</span><br><span class="line"><span class="comment"># 驱动路径</span></span><br><span class="line">path = <span class="string">r'C:\Users\ZBLi\Desktop\ziliao\chromedriver.exe'</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 创建浏览器对象</span></span><br><span class="line">browser = webdriver.Chrome(executable_path=path, chrome_options=chrome_options)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 上网</span></span><br><span class="line">url = <span class="string">'http://www.baidu.com/'</span></span><br><span class="line">browser.get(url)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"> </span><br><span class="line">browser.save_screenshot(<span class="string">'baidu.png'</span>)</span><br><span class="line"> </span><br><span class="line">browser.quit()</span><br></pre></td></tr></table></figure>
<h1 id="session处理cookie"><a href="#session处理cookie" class="headerlink" title="session处理cookie"></a>session处理cookie</h1><p> <code>cookie概念</code>：当用户通过浏览器首次访问一个域名时，访问的web服务器会给客户端发送数据，以保持web服务器与客户端之间的状态保持，这些数据就是cookie。</p>
<p><code>cookie作用</code>：我们在浏览器中，经常涉及到数据的交换，比如你登录邮箱，登录一个页面。我们经常会在此时设置30天内记住我，或者自动登录选项。那么它们是怎么记录信息的呢，答案就是今天的主角cookie了，Cookie是由HTTP服务器设置的，保存在浏览器中，但HTTP协议是一种无状态协议，在数据交换完毕后，服务器端和客户端的链接就会关闭，每次交换数据都需要建立新的链接。就像我们去超市买东西，没有积分卡的情况下，我们买完东西之后，超市没有我们的任何消费信息，但我们办了积分卡之后，超市就有了我们的消费信息。cookie就像是积分卡，可以保存积分，商品就是我们的信息，超市的系统就像服务器后台，http协议就是交易的过程。</p>
<p>所以有时爬取到文件中的数据，不是个人页面的数据，而是登陆的首页面</p>
<h2 id="使用-4"><a href="#使用-4" class="headerlink" title="使用"></a>使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment">#登录请求的url（通过抓包工具获取）</span></span><br><span class="line">    post_url = <span class="string">'http://www.renren.com/ajaxLogin/login?1=1&amp;uniqueTimestamp=201873958471'</span></span><br><span class="line">    <span class="comment">#创建一个session对象，该对象会自动将请求中的cookie进行存储和携带</span></span><br><span class="line">    session = requests.Session()</span><br><span class="line">   <span class="comment">#伪装UA</span></span><br><span class="line">    headers=&#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    formdata = &#123;</span><br><span class="line">        <span class="string">'email'</span>: <span class="string">'1316231847'</span>,</span><br><span class="line">        <span class="string">'icode'</span>: <span class="string">''</span>,</span><br><span class="line">        <span class="string">'origURL'</span>: <span class="string">'http://www.renren.com/home'</span>,</span><br><span class="line">        <span class="string">'domain'</span>: <span class="string">'renren.com'</span>,</span><br><span class="line">        <span class="string">'key_id'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'captcha_type'</span>: <span class="string">'web_login'</span>,</span><br><span class="line">        <span class="string">'password'</span>: <span class="string">'7b456e6c3eb6615b2e122a2942ef3845da1f91e3de075179079a3b84952508e4'</span>,</span><br><span class="line">        <span class="string">'rkey'</span>: <span class="string">'44fd96c219c593f3c9612360c80310a3'</span>,</span><br><span class="line">        <span class="string">'f'</span>: <span class="string">'https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3Dm7m_NSUp5Ri_ZrK5eNIpn_dMs48UAcvT-N_kmysWgYW%26wd%3D%26eqid%3Dba95daf5000065ce000000035b120219'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#使用session发送请求，目的是为了将session保存该次请求中的cookie</span></span><br><span class="line">    session.post(url=post_url,data=formdata,headers=headers)</span><br><span class="line"></span><br><span class="line">    get_url = <span class="string">'http://www.renren.com/960481378/profile'</span></span><br><span class="line">    <span class="comment">#再次使用session进行请求的发送，该次请求中已经携带了cookie</span></span><br><span class="line">    response = session.get(url=get_url,headers=headers)</span><br><span class="line">    <span class="comment">#设置响应内容的编码格式</span></span><br><span class="line">    response.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    <span class="comment">#将响应内容写入文件</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./renren.html'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(response.text)</span><br></pre></td></tr></table></figure>
<h1 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h1><p>一些网站会有相应的反爬虫措施，例如很多网站会检测某一段时间某个IP的访问次数，如果访问频率太快以至于看起来不像正常访客，它可能就会会禁止这个IP的访问。所以我们需要设置一些代理IP，每隔一段时间换一个代理IP，就算IP被禁止，依然可以换个IP继续爬取。</p>
<h2 id="代理的分类："><a href="#代理的分类：" class="headerlink" title="代理的分类："></a>代理的分类：</h2><ul>
<li>正向代理：代理客户端获取数据。正向代理是为了保护客户端防止被追究责任。</li>
<li>反向代理：代理服务器提供数据。反向代理是为了保护服务器或负责负载均衡。</li>
</ul>
<h2 id="免费代理ip提供网站"><a href="#免费代理ip提供网站" class="headerlink" title="免费代理ip提供网站"></a>免费代理ip提供网站</h2><ul>
<li><a href="http://www.goubanjia.com/" target="_blank" rel="noopener">http://www.goubanjia.com/</a></li>
<li>西祠代理</li>
<li>快代理</li>
</ul>
<h2 id="使用-5"><a href="#使用-5" class="headerlink" title="使用"></a>使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#不同的代理IP</span></span><br><span class="line">    proxy_list = [</span><br><span class="line">        &#123;<span class="string">"http"</span>: <span class="string">"112.115.57.20:3128"</span>&#125;,</span><br><span class="line">        &#123;<span class="string">'http'</span>: <span class="string">'121.41.171.223:3128'</span>&#125;</span><br><span class="line">    ]</span><br><span class="line"><span class="comment">#随机获取UA和代理IP</span></span><br><span class="line">    header = random.choice(header_list)</span><br><span class="line">    proxy = random.choice(proxy_list)</span><br><span class="line">    url = <span class="string">'http://www.baidu.com/s?ie=UTF-8&amp;wd=ip'</span></span><br><span class="line"><span class="comment">#参数3：设置代理</span></span><br><span class="line">    response = requests.get(url=url,headers=header,proxies=proxy)</span><br></pre></td></tr></table></figure>
<h1 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h1><p>基于线程池的爬取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="comment">#安装fake-useragent库:pip install fake-useragent</span></span><br><span class="line"><span class="comment">#导入线程池模块</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"><span class="comment">#实例化线程池对象</span></span><br><span class="line">pool = Pool()</span><br><span class="line">url = <span class="string">'http://www.pearvideo.com/category_1'</span></span><br><span class="line"><span class="comment">#随机产生UA</span></span><br><span class="line">ua = UserAgent().random</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:ua</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#获取首页页面数据</span></span><br><span class="line">page_text = requests.get(url=url,headers=headers).text</span><br><span class="line"><span class="comment">#对获取的首页页面数据中的相关视频详情链接进行解析</span></span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">li_list = tree.xpath(<span class="string">'//div[@id="listvideoList"]/ul/li'</span>)</span><br><span class="line"></span><br><span class="line">detail_urls = []<span class="comment">#存储二级页面的url</span></span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    detail_url = <span class="string">'http://www.pearvideo.com/'</span>+li.xpath(<span class="string">'./div/a/@href'</span>)[<span class="number">0</span>]</span><br><span class="line">    title = li.xpath(<span class="string">'.//div[@class="vervideo-title"]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">    detail_urls.append(detail_url)</span><br><span class="line">    </span><br><span class="line">vedio_urls = []<span class="comment">#存储视频的url</span></span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> detail_urls:</span><br><span class="line">    page_text = requests.get(url=url,headers=headers).text</span><br><span class="line">    vedio_url = re.findall(<span class="string">'srcUrl="(.*?)"'</span>,page_text,re.S)[<span class="number">0</span>]</span><br><span class="line">    vedio_urls.append(vedio_url) </span><br><span class="line"><span class="comment">#使用线程池进行视频数据下载    </span></span><br><span class="line">func_request = <span class="keyword">lambda</span> link:requests.get(url=link,headers=headers).content</span><br><span class="line">video_data_list = pool.map(func_request,vedio_urls)</span><br><span class="line"><span class="comment">#使用线程池进行视频数据保存</span></span><br><span class="line">func_saveData = <span class="keyword">lambda</span> data:save(data)</span><br><span class="line">pool.map(func_saveData,video_data_list)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(data)</span>:</span></span><br><span class="line">    fileName = str(random.randint(<span class="number">1</span>,<span class="number">10000</span>))+<span class="string">'.mp4'</span></span><br><span class="line">    <span class="keyword">with</span> open(fileName,<span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(data)</span><br><span class="line">        print(fileName+<span class="string">'已存储'</span>)</span><br><span class="line">        </span><br><span class="line">pool.close()</span><br><span class="line">pool.join()</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

	<div>
	  
		<div>
    
        <div style="text-align:center;color: #555;font-size:14px;">-------------The End-------------</div>
    
</div>

	  
    </div>

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/20/Notes/" rel="next" title="Notes">
                <i class="fa fa-chevron-left"></i> Notes
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/01/scrapy/" rel="prev" title="基于Python的爬虫之二 Scrapy爬虫框架">
                基于Python的爬虫之二 Scrapy爬虫框架 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>
  



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">yaosir0317</p>
              <p class="site-description motion-element" itemprop="description">yaosir0317个人博客,持续更新中...</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yaosir0317" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是爬虫"><span class="nav-number">1.</span> <span class="nav-text">什么是爬虫</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#哪些语言可以实现爬虫"><span class="nav-number">2.</span> <span class="nav-text">哪些语言可以实现爬虫</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#爬虫的分类"><span class="nav-number">3.</span> <span class="nav-text">爬虫的分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#通用爬虫"><span class="nav-number">3.1.</span> <span class="nav-text">通用爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#聚焦爬虫"><span class="nav-number">3.2.</span> <span class="nav-text">聚焦爬虫</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#robots-txt协议"><span class="nav-number">4.</span> <span class="nav-text">robots.txt协议</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#反爬虫"><span class="nav-number">5.</span> <span class="nav-text">反爬虫</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#反反爬虫"><span class="nav-number">6.</span> <span class="nav-text">反反爬虫</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#requests模块"><span class="nav-number">7.</span> <span class="nav-text">requests模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#请求载体身份标识的伪装："><span class="nav-number">7.1.</span> <span class="nav-text">请求载体身份标识的伪装：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用"><span class="nav-number">7.2.</span> <span class="nav-text">使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正解解析"><span class="nav-number">8.</span> <span class="nav-text">正解解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#常用正则表达式"><span class="nav-number">8.1.</span> <span class="nav-text">常用正则表达式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Xpath解析"><span class="nav-number">9.</span> <span class="nav-text">Xpath解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#常用xpath表达式"><span class="nav-number">9.1.</span> <span class="nav-text">常用xpath表达式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#etree"><span class="nav-number">9.2.</span> <span class="nav-text">etree</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用-1"><span class="nav-number">9.2.1.</span> <span class="nav-text">使用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BeautifulSoup解析"><span class="nav-number">10.</span> <span class="nav-text">BeautifulSoup解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用-2"><span class="nav-number">10.1.</span> <span class="nav-text">使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图片懒加载"><span class="nav-number">11.</span> <span class="nav-text">图片懒加载</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#实现"><span class="nav-number">11.1.</span> <span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图片验证码"><span class="nav-number">12.</span> <span class="nav-text">图片验证码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#处理验证码的实现流程"><span class="nav-number">12.1.</span> <span class="nav-text">处理验证码的实现流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#selenium"><span class="nav-number">13.</span> <span class="nav-text">selenium</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#浏览器的驱动程序（以谷歌浏览器为例）"><span class="nav-number">13.1.</span> <span class="nav-text">浏览器的驱动程序（以谷歌浏览器为例）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用-3"><span class="nav-number">13.2.</span> <span class="nav-text">使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#phantomJs"><span class="nav-number">13.3.</span> <span class="nav-text">phantomJs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#谷歌无头浏览器"><span class="nav-number">13.4.</span> <span class="nav-text">谷歌无头浏览器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#session处理cookie"><span class="nav-number">14.</span> <span class="nav-text">session处理cookie</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用-4"><span class="nav-number">14.1.</span> <span class="nav-text">使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#代理"><span class="nav-number">15.</span> <span class="nav-text">代理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#代理的分类："><span class="nav-number">15.1.</span> <span class="nav-text">代理的分类：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#免费代理ip提供网站"><span class="nav-number">15.2.</span> <span class="nav-text">免费代理ip提供网站</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用-5"><span class="nav-number">15.3.</span> <span class="nav-text">使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线程池"><span class="nav-number">16.</span> <span class="nav-text">线程池</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yaosir0317</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>
  

  
  
    <script type="text/javascript" src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script>
  

  
  
    <script type="text/javascript" src="//cdn.jsdelivr.net/jquery.lazyload/1.9.3/jquery.lazyload.min.js"></script>
  

  
  
    <script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.min.js"></script>
  

  
  
    <script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.ui.min.js"></script>
  

  
  
    <script type="text/javascript" src="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
  

  
  
    <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
